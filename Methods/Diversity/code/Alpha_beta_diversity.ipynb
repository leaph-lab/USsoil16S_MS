{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nRf_C-bJct9C"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skbio import TreeNode\n",
    "from skbio.diversity import beta_diversity\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from skbio.tree import TreeNode\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load relative abundance data for each ecotype\n",
    "abun_relabun = pd.read_csv(\"input/abun_relabun.csv\", index_col = 0)\n",
    "rare_relabun = pd.read_csv(\"input/rare_relabun.csv\", index_col = 0)\n",
    "gen_relabun = pd.read_csv(\"input/gen_relabun.csv\", index_col = 0)\n",
    "spe_relabun = pd.read_csv(\"input/spe_relabun.csv\", index_col = 0)\n",
    "\n",
    "# Read the phylogenetic tree from the Newick file\n",
    "with open(\"input/new_rOTU_tree.nwk\", 'r') as file:\n",
    "    newick_string = file.read()\n",
    "\n",
    "# Parse the Newick string and create a TreeNode object\n",
    "tree = TreeNode.read(StringIO(newick_string))\n",
    "rooted_tree = tree.root_at_midpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shannon-Weiner diversity for each ecotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def shannon_diversity(relabun):\n",
    "\n",
    "    # Remove zeros to avoid log(0) issues\n",
    "    relabun = relabun.replace(0, np.nan).dropna()\n",
    "\n",
    "    # Calculate Shannon entropy\n",
    "    entropy = -np.sum(relabun * np.log(relabun))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "# Calculate Shannon-Weiner Diversity for each sample\n",
    "abun_shannon = abun_relabun.apply(shannon_diversity, axis=0)\n",
    "rare_shannon = rare_relabun.apply(shannon_diversity, axis=0)\n",
    "gen_shannon = gen_relabun.apply(shannon_diversity, axis=0)\n",
    "spe_shannon = spe_relabun.apply(shannon_diversity, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_shannon = pd.concat([abun_shannon, rare_shannon, gen_shannon, spe_shannon], axis=1)\n",
    "column_names = ['Abundant taxa', 'Rare taxa', 'Generalists', 'Specialists']\n",
    "df_shannon.columns = column_names\n",
    "\n",
    "df_shannon.to_csv(\"output/ecotypes_shannon.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SksBzbrhFzrn"
   },
   "source": [
    "# Weighted Unifrac distance for each ecotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_unifrac_distance(relative_abundance, rooted_tree):\n",
    "\n",
    "    relative_abundance.index = relative_abundance.index.str.replace('_', ' ', regex=False) # Replace underscores in the index\n",
    "    relative_abundance = relative_abundance.multiply(1000) # multiply by 1000 otherwise the values are too small; all distances would be zero\n",
    "\n",
    "    # Ensure that OTUs present in the phylogenetic tree are also present in the abundance DataFrame\n",
    "    common_otus = set(relative_abundance.index) & set(n.name for n in rooted_tree.tips())\n",
    "    relative_abundance_com = relative_abundance[relative_abundance.index.isin(common_otus)]\n",
    "\n",
    "    # Calculate the UniFrac distance matrix\n",
    "    unifrac_distance_matrix = beta_diversity(\"weighted_unifrac\", relative_abundance_com.values.T, ids=relative_abundance_com.columns, taxa=relative_abundance_com.index, tree=rooted_tree)\n",
    "    distance_df = pd.DataFrame(data=unifrac_distance_matrix.data,columns=unifrac_distance_matrix.ids, index=unifrac_distance_matrix.ids)\n",
    "\n",
    "    return distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_df_abun = weighted_unifrac_distance(abun_relabun, rooted_tree)\n",
    "distance_df_abun.to_csv('output/weighted_unifrac_abun.csv')\n",
    "\n",
    "distance_df_rare = weighted_unifrac_distance(rare_relabun, rooted_tree)\n",
    "distance_df_rare.to_csv('output/weighted_unifrac_rare.csv')\n",
    "\n",
    "distance_df_gen = weighted_unifrac_distance(gen_relabun, rooted_tree)\n",
    "distance_df_gen.to_csv('output/weighted_unifrac_gen.csv')\n",
    "\n",
    "distance_df_spe = weighted_unifrac_distance(spe_relabun, rooted_tree)\n",
    "distance_df_spe.to_csv('output/weighted_unifrac_spe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bray-Curtis distance for each ecotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bray_curtis_distance(relative_abundance):\n",
    "\n",
    "    # Calculate the the pairwise Bray-Curtis distances\n",
    "    bc_distance_matrix = pdist(relative_abundance.T, metric='braycurtis')\n",
    "\n",
    "    # Convert the distance matrix to a square form\n",
    "    bc_distance_matrix_square = squareform(bc_distance_matrix)\n",
    "\n",
    "    distance_df = pd.DataFrame(bc_distance_matrix_square, index=relative_abundance.columns, columns=relative_abundance.columns)\n",
    "\n",
    "    return distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_distance_df_abun = bray_curtis_distance(abun_relabun)\n",
    "\n",
    "bc_distance_df_rare = bray_curtis_distance(rare_relabun)\n",
    "\n",
    "bc_distance_df_gen = bray_curtis_distance(gen_relabun)\n",
    "\n",
    "bc_distance_df_spe = bray_curtis_distance(spe_relabun)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
